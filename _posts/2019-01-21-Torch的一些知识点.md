---
layout: post
title:  "Torch的一些知识点"
date:   2019-01-21 20:37:56 +0800
<!-- categories: RL -->
tags: Torch 神经网络
---

* content
{:toc}


## 1.构建神经网络时候的注意点
- 定义优化器和损失函数
```python
optimizer = torch.optim.SGD(net.parameters(), lr=0.2)`
loss_func = torch.nn.MSELoss()
```
- 每次反向传播之后要清除梯度
```python
optimizer.zero_grad()   # clear gradients for next train
optimizer.step()       # apply gradients
```
- 快速搭建神经网络
```python
# easy and fast way to build your network
net1 = torch.nn.Sequential(
    torch.nn.Linear(1, 10),
    torch.nn.ReLU(),
    torch.nn.Linear(10, 1)
)
```
输出结果：
```python
Sequential(
  (0): Linear(in_features=1, out_features=10, bias=True)
  (1): ReLU()
  (2): Linear(in_features=10, out_features=1, bias=True)
)
```
- 神经网络的保存和提取

保存神经网络有两种方式
```python
# 2 ways to save the net
torch.save(net1, 'net.pkl')  # save entire net
torch.save(net1.state_dict(), 'net_params.pkl')   # save only the parameters
```
这两种方式在加载的时候也会有所区别
```python
# restore entire net1 to net2
net2 = torch.load('net.pkl')
# restore only the parameters in net1 to net3
net3 = torch.nn.Sequential(
    torch.nn.Linear(1, 10),
    torch.nn.ReLU(),
    torch.nn.Linear(10, 1)
)
# copy net1's parameters into net3
net3.load_state_dict(torch.load('net_params.pkl'))
```
- 神经网络批训练

利用torch.utils.data.DataLoader进行批训练
```python
import torch
import torch.utils.data as Data
torch.manual_seed(1)                # reproducible
BATCH_SIZE = 5
x = torch.linspace(1, 10, 10)       # this is x data (torch tensor)
y = torch.linspace(10, 1, 10)       # this is y data (torch tensor)
torch_dataset = Data.TensorDataset(x, y)
loader = Data.DataLoader(
    dataset=torch_dataset,      # torch TensorDataset format
    batch_size=BATCH_SIZE,      # mini batch size
    shuffle=True,               # random shuffle for training
    num_workers=2,              # subprocesses for loading data
)
def show_batch():
    for epoch in range(3):   # train entire dataset 3 times
        for step, (batch_x, batch_y) in enumerate(loader):  # for each training step
            # train your data...
            print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',
                  batch_x.numpy(), '| batch y: ', batch_y.numpy())
```
- CNN卷积神经网络

用一个 class 来建立 CNN 模型. 这个 CNN 整体流程是 卷积(Conv2d) -> 激励函数(ReLU) -> 池化, 向下采样 (MaxPooling) -> 再来一遍 -> 展平多维的卷积成的特征图 -> 接入全连接层 (Linear) -> 输出
```python
self.conv1 = nn.Sequential(  # input shape (1, 28, 28)
        nn.Conv2d(
            in_channels=1,      # input height
            out_channels=16,    # n_filters
            kernel_size=5,      # filter size
            stride=1,           # filter movement/step
            padding=2,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1
        ),      # output shape (16, 28, 28)
        nn.ReLU(),    # activation
        nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 14, 14)
    )
```
未完待续……