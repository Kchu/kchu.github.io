---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
2nd-year PhD student in Computer Science, University of Hamburg, [Knowledge Technology (WTM)](https://www.inf.uni-hamburg.de/en/inst/ab/wtm.html) group, advised by [Prof. Stefan Wermter](https://www.inf.uni-hamburg.de/en/inst/ab/wtm/people/wermter.html).

M.Sc in Computer Science and Technology, [University of Electronic Science and Technology of China](https://en.uestc.edu.cn/), advised by [Prof. William Zhu](https://scholar.google.com/citations?hl=zh-CN&user=GIwXoWAAAAAJ), 2018-2021.

B.E. in Spatial Information and Digital Technology, [University of Electronic Science and Technology of China](https://en.uestc.edu.cn/), advised by [Prof. Fen Chen](https://scholar.google.com/citations?hl=zh-CN&user=U0VZ1IkAAAAJ), 2014-2018.

I have a broad interest in Reinforcement Learning, Large Language Models (LLMs), and Robotics, including 1). how to utilize LLMs to enable RL agents learn more efficiently in (bimanual) robotic tasks; 2). how to employ LLMs in long-horizon robotic tasks; 3) how to deploy learning models (foundation models, RL models) in humanoid robots for everyday tasks in real world, etc.

The Future of Embodied Intelligence is Now.

## What's New

[2024.03] The project website of [LABOR Agent: Large Language Models for Orchestrating Bimanual Robots](https://labor-agent.github.io/) is released! Paper in arxiv version can be found at [here](https://arxiv.org/abs/2404.02018)

[2024.02] I am glad to be served as technical committee member of the 2024 IEEE International Conference on
Robotics and Automation (ICRA 2024) [Workshop on Human-aligned Reinforcement Learning for Autonomous Agents and Robots](https://harlworkshop.github.io/index.html)

[2024.02] Our paper **Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic** has been accepted at [COLING 2024](https://lrec-coling-2024.org/).

[2023.11] Our paper **Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models** has been accepted as oral presentation at the 7th Conference on Robot Learning (CoRL 2023) [Workshop on Bridging the Gap between Cognitive Science and Robot Learning in the Real World: Progresses and New Directions](https://yantianzha.github.io/crl.github.io/)

<!-- I mainly engaged in Deep Reinforcement Learning (RL) and Transfer/Lifelong RL during my master’s study. Recently, our manuscript about Lifelong RL is accepted by the 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC). Currently, I am engaged in the theoretical research for non-model-based, data-driven adaptive optimal control design, which is based on RL theory and ADP. Compared to traditional control methods, learning-based control methods have been attracted extensive attention and can be widely used in practical applications such as robotics and unmanned vehicles. -->
 
<!-- During my studying periods, I have proficiency in programming (Python, Matlab, and C/C++) and Deep Learning frameworks (PyTorch). I reproduced several Deep RL algorithms with PyTorch and Clustering algorithms with Python/Matlab. While practice is driven by theory, I believe problems in practical applications, such as robotics, and unmanned driving, will promote the vigorous development of theory. -->

<!-- My future research plan is mainly about Reinforcement/Robot Learning in the real world, which is challenging and forward-looking. Briefly speaking, how to effectively utilize the previous knowledge when solving new tasks is the main/eternal topic in these fields. As we all know, Deep RL combines DL’s perception ability with the decision-making ability of RL, which is closer to the way of human thinking. Despite the great success of Deep RL, there are still some challenges in the development of RL in the real world, like unavailable reward functions, exploration-exploitation trade-off, unbearable sample complexity, sim-to-real gap, dynamic environments, and so on. At present, the study about that is immature but promising. In addition, with the deepening of research, how to introduce technologies/theories in Machine Learning (like Deep Neural Networks, Computer Vision, Natural Language Processing, Imitation/Representation/Curriculum Learning) to solve Robotic problems in reality, including Grasping/Manipulation/Path planning, etc., is an extremely enlightening perspective. In addition, how to further study RL from the perspective of neuroscience is an inevitable way in the future. -->

Glad to discuss anything! Please contact me at kun.chu at uni-hamburg.de