---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a research assistant at the University of Technology and Electronic Science of China (UESTC). I had been awarded my master's degree in Computer Science and Technology at UESTC, supervised by Prof. William Zhu.
 
I mainly engaged in Deep Reinforcement Learning (RL) and Transfer/Lifelong RL during my master’s study. Recently, our manuscript about Lifelong RL is accepted by the 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC). Currently, I am engaged in the theoretical research for non-model-based, data-driven adaptive optimal control design, which is based on RL theory and approximate/adaptive dynamic programming (ADP). Compared to traditional control methods, learning-based control methods have been attracted extensive attention and can be widely used in practical applications such as robotics and unmanned vehicles.
 
During my studying periods, I have proficiency in programming (Python, Matlab, and C/C++) and Deep Learning frameworks (PyTorch/Tensorflow). I reproduced several Deep RL algorithms with PyTorch and Cluster algorithms with Python/Matlab. While practice is driven by theory, I believe problems in practical applications, such as robotics, and unmanned driving, will promote the vigorous development of theory.

My future research plan is mainly about Reinforcement/Robotic Learning in the real world, which is challenging and forward-looking. Briefly speaking, how to effectively utilize the previous knowledge when solving new tasks is the main/eternal topic in these fields. As we all know, Deep RL combines DL’s perception ability with the decision-making ability of RL, which is closer to the way of human thinking. Despite the great success of Deep RL, there are still some challenges in the development of RL in the real world, like unavailable reward functions, exploration-exploitation trade-off, unbearable sample complexity, sim-to-real gap, dynamic environments, and so on. At present, the study about that is immature but promising. In addition, with the deepening of research, how to introduce technologies/theories in Machine Learning (like Deep Neural Networks, Computer Vision, Natural Language Processing, Imitation/Representation/Curriculum Learning) to solve Robotic problems in reality, including Grasping/Manipulation/Path planning, etc., is an extremely enlightening perspective. In addition, how to further study RL from the perspective of neuroscience is an inevitable way in the future.

Glad to discuss anything! Please contact me at <kun_chu@outlook.com>. 